{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ottawa dataset processing\n",
    "\n",
    "1. extract anomaly column\n",
    "2. resampling to 20kHz\n",
    "3. adding label\n",
    "4. combine health and faulty data\n",
    "5. extract features same as NASA data\n",
    "6. save features to features_ottawa.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.signal import butter, filtfilt, resample\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import kurtosis, skew\n",
    "import joblib\n",
    "\n",
    "# File paths\n",
    "healthy_file = \"datat/H_H_8_1.csv\" # data without anomaly, 10 seconds of data, sampling rate of 42 kHz\n",
    "faulty_file = \"datat/F_B_8_1.csv\" # data with all anomaly, 10 seconds of data, sampling rate of 42 kHz\n",
    "output_features = \"Ottawa_features.csv\"\n",
    "\n",
    "# Read files\n",
    "healthy_data = pd.read_csv(healthy_file)\n",
    "faulty_data = pd.read_csv(faulty_file)\n",
    "\n",
    "# Select Accelerometer 1, which contains anomalies\n",
    "healthy_channel = healthy_data[\"Accelerometer 1 (m/s^2)\"]\n",
    "faulty_channel = faulty_data[\"Accelerometer 1 (m/s^2)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a low-pass filter\n",
    "def low_pass_filter(signal, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return filtfilt(b, a, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "sampling_rate_original = 42000  # 42 kHz\n",
    "sampling_rate_target = 20000    # 20 kHz\n",
    "cutoff_frequency = 10000        # 10 kHz\n",
    "window_size = 512               # Window size for segmentation\n",
    "stride = 256                    # Stride for sliding window\n",
    "\n",
    "# Apply low-pass filtering\n",
    "healthy_filtered = low_pass_filter(healthy_channel, cutoff_frequency, sampling_rate_original)\n",
    "faulty_filtered = low_pass_filter(faulty_channel, cutoff_frequency, sampling_rate_original)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the data\n",
    "downsample_factor = sampling_rate_original / sampling_rate_target\n",
    "healthy_downsampled = resample(healthy_filtered, int(len(healthy_filtered) / downsample_factor))\n",
    "faulty_downsampled = resample(faulty_filtered, int(len(faulty_filtered) / downsample_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy Downsampled: 200000, Expected: 200000\n",
      "Faulty Downsampled: 200000, Expected: 200000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Healthy Downsampled: {len(healthy_downsampled)}, Expected: {sampling_rate_target * 10}\")\n",
    "print(f\"Faulty Downsampled: {len(faulty_downsampled)}, Expected: {sampling_rate_target * 10}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the downsampled data with stride\n",
    "def segment_signal_with_stride(signal, window_size, stride):\n",
    "    return [signal[i:i+window_size] for i in range(0, len(signal) - window_size + 1, stride)]\n",
    "\n",
    "# Segment the downsampled data with stride and ensure NumPy array output\n",
    "healthy_segments = np.array(segment_signal_with_stride(healthy_downsampled, window_size, stride))\n",
    "faulty_segments = np.array(segment_signal_with_stride(faulty_downsampled, window_size, stride))\n",
    "\n",
    "# Extract features from each window\n",
    "def extract_features(windows):\n",
    "    return np.column_stack([\n",
    "        np.mean(windows, axis=1),\n",
    "        np.std(windows, axis=1),\n",
    "        np.max(windows, axis=1),\n",
    "        np.min(windows, axis=1),\n",
    "        kurtosis(windows, axis=1),\n",
    "        skew(windows, axis=1),\n",
    "        np.sqrt(np.mean(windows**2, axis=1)),  # RMS\n",
    "        np.ptp(windows, axis=1),  # Amplitude Range\n",
    "        np.max(windows, axis=1) / (np.sqrt(np.mean(windows**2, axis=1)) + 1e-10),  # Peak Factor\n",
    "        np.sum(np.diff(np.sign(windows), axis=1) != 0, axis=1)  # Zero-Crossing Rate\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_ottawa = np.vstack([\n",
    "    extract_features(healthy_segments),\n",
    "    extract_features(faulty_segments)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ottawa Scaler saved as 'scaler_ottawa.pkl'.\n"
     ]
    }
   ],
   "source": [
    "# Train a new StandardScaler on Ottawa dataset\n",
    "scaler_ottawa = StandardScaler()\n",
    "X_ottawa_scaled = scaler_ottawa.fit_transform(X_ottawa)  # Compute scaling\n",
    "\n",
    "# Save this new scaler for future use\n",
    "joblib.dump(scaler_ottawa, \"scaler_ottawa.pkl\")\n",
    "print(\"New Ottawa Scaler saved as 'scaler_ottawa.pkl'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_ottawa saved as: Ottawa_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Combine features and labels\n",
    "y_combined = np.concatenate((np.zeros(len(healthy_segments)), np.ones(len(faulty_segments))), axis=0)\n",
    "\n",
    "# Save the standardized features to CSV\n",
    "features_df = pd.DataFrame(X_ottawa_scaled, columns=[\n",
    "    'Mean', 'Std', 'Max', 'Min', 'Kurtosis', 'Skewness', 'RMS', 'AmplitudeRange', 'PeakFactor', 'ZeroCrossings'\n",
    "])\n",
    "features_df['AnomalyLabel'] = y_combined\n",
    "features_df.to_csv(output_features, index=False)\n",
    "print(f\"features_ottawa saved as: {output_features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
