{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with Ottawa feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the Ottawa dataset\n",
    "ottawa_data = pd.read_csv(\"Ottawa_features.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X_ottawa = ottawa_data.drop(columns=[\"AnomalyLabel\"]).values \n",
    "y_ottawa = ottawa_data[\"AnomalyLabel\"].values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Transformer Autoencoder \n",
    "class TransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers, dropout_rate):\n",
    "        super(TransformerAutoencoder, self).__init__()\n",
    "        adjusted_dim = hidden_dim * num_heads \n",
    "        self.input_projection = nn.Linear(input_dim, adjusted_dim)\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=adjusted_dim, nhead=num_heads, dropout=dropout_rate, norm_first=True\n",
    "            ),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(adjusted_dim, input_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        x = x.unsqueeze(0) \n",
    "        x = self.encoder(x)\n",
    "        x = x.squeeze(0)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diff transformer\n",
    "class DiffTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1, lambda_init=0.8):\n",
    "        super(DiffTransformerEncoderLayer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.lambda_scalar = nn.Parameter(torch.tensor(lambda_init, requires_grad=True))  \n",
    "\n",
    "        # 投影层\n",
    "        self.qk_proj = nn.Linear(d_model, d_model * 2)  \n",
    "        self.v_proj = nn.Linear(d_model, d_model)\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # FFN 和 LayerNorm\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # 计算 Q1, Q2, K1, K2, V\n",
    "        qk = self.qk_proj(src).chunk(2, dim=-1)  \n",
    "        Q1, Q2, K1, K2 = qk[0], qk[1], qk[0], qk[1]\n",
    "        V = self.v_proj(src)\n",
    "\n",
    "        A1 = torch.softmax(Q1 @ K1.transpose(-2, -1) / (self.d_model ** 0.5), dim=-1)\n",
    "        A2 = torch.softmax(Q2 @ K2.transpose(-2, -1) / (self.d_model ** 0.5), dim=-1)\n",
    "\n",
    "        attention_output = (A1 - self.lambda_scalar * A2) @ V\n",
    "        attention_output = self.out_proj(attention_output)\n",
    "\n",
    "        src = src + self.dropout(self.norm1(attention_output))\n",
    "        src = src + self.dropout(self.norm2(self.ffn(src)))\n",
    "        return src\n",
    "\n",
    "# diff autoencoder\n",
    "class DiffTransformerAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_heads, num_layers):\n",
    "        super(DiffTransformerAutoencoder, self).__init__()\n",
    "        adjusted_dim = hidden_dim * num_heads  \n",
    "        self.input_projection = nn.Linear(input_dim, adjusted_dim)\n",
    "        self.encoder = nn.ModuleList([\n",
    "            DiffTransformerEncoderLayer(d_model=adjusted_dim, nhead=num_heads)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoder = nn.Linear(adjusted_dim, input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_projection(x)\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Elena\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "C:\\Users\\Elena\\AppData\\Local\\Temp\\ipykernel_8144\\3025643543.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  transformer_model.load_state_dict(torch.load(\"Transformer.pth\"))\n",
      "C:\\Users\\Elena\\AppData\\Local\\Temp\\ipykernel_8144\\3025643543.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  diff_transformer_model.load_state_dict(torch.load(\"Diff_Transformer.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffTransformerAutoencoder(\n",
       "  (input_projection): Linear(in_features=10, out_features=512, bias=True)\n",
       "  (encoder): ModuleList(\n",
       "    (0-1): 2 x DiffTransformerEncoderLayer(\n",
       "      (qk_proj): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): Linear(in_features=2048, out_features=512, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Transformer autoencoder\n",
    "transformer_model = TransformerAutoencoder(input_dim=X_ottawa.shape[1], hidden_dim=128, num_heads=4, num_layers=2, dropout_rate=0.1)\n",
    "transformer_model.load_state_dict(torch.load(\"Transformer.pth\"))\n",
    "transformer_model.eval()\n",
    "\n",
    "# Load DiffTransformer autoencoder\n",
    "diff_transformer_model = DiffTransformerAutoencoder(input_dim=X_ottawa.shape[1], hidden_dim=128, num_heads=4, num_layers=2)\n",
    "diff_transformer_model.load_state_dict(torch.load(\"Diff_Transformer.pth\"))\n",
    "diff_transformer_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_ottawa_tensor = torch.tensor(X_ottawa, dtype=torch.float32).to(device)\n",
    "transformer_model.to(device)\n",
    "diff_transformer_model.to(device)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    transformer_reconstructed = transformer_model(X_ottawa_tensor)\n",
    "    diff_transformer_reconstructed = diff_transformer_model(X_ottawa_tensor)\n",
    "\n",
    "# Compute Reconstruction errors \n",
    "transformer_errors = torch.mean((X_ottawa_tensor - transformer_reconstructed) ** 2, dim=1).cpu().numpy()\n",
    "diff_transformer_errors = torch.mean((X_ottawa_tensor - diff_transformer_reconstructed) ** 2, dim=1).cpu().numpy()\n",
    "\n",
    "# Normalize rec error\n",
    "transformer_errors = (transformer_errors - np.mean(transformer_errors)) / np.std(transformer_errors)\n",
    "diff_transformer_errors = (diff_transformer_errors - np.mean(diff_transformer_errors)) / np.std(diff_transformer_errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold for transformer\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_ottawa, transformer_errors)\n",
    "optimal_idx = np.argmax(tpr - fpr) \n",
    "optimal_threshold_transformer = thresholds[optimal_idx]\n",
    "\n",
    "# Find optimal threshold for diffTransformer\n",
    "fpr, tpr, thresholds = roc_curve(y_ottawa, diff_transformer_errors)\n",
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold_diff_transformer = thresholds[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert errors into anomaly predictions using optimal threshold\n",
    "transformer_preds = (transformer_errors > optimal_threshold_transformer).astype(int)\n",
    "diff_transformer_preds = (diff_transformer_errors > optimal_threshold_diff_transformer).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer performance matrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.54      0.79      0.64       780\n",
      "      Faulty       0.60      0.32      0.42       780\n",
      "\n",
      "    accuracy                           0.55      1560\n",
      "   macro avg       0.57      0.55      0.53      1560\n",
      "weighted avg       0.57      0.55      0.53      1560\n",
      "\n",
      "DiffTransformer performance matrics:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Healthy       0.64      0.99      0.78       780\n",
      "      Faulty       0.99      0.44      0.60       780\n",
      "\n",
      "    accuracy                           0.71      1560\n",
      "   macro avg       0.81      0.71      0.69      1560\n",
      "weighted avg       0.81      0.71      0.69      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Print evaluation metrics for Transformer\n",
    "print(\"Transformer performance matrics:\")\n",
    "print(classification_report(y_ottawa, transformer_preds, target_names=[\"Healthy\", \"Faulty\"]))\n",
    "\n",
    "# Print evaluation metrics for DiffTransformer\n",
    "print(\"DiffTransformer performance matrics:\")\n",
    "print(classification_report(y_ottawa, diff_transformer_preds, target_names=[\"Healthy\", \"Faulty\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Healthy recall is 0.99 for diff transformer show the model correctly identified all samples while the value for transformer is significanly lower. Faulty precision for diff is 0.99 as well means it can correctly predicts a sample as faulty. For faulty recall both are lower but diff is still performing better than transformer. The overall accuracy of diff is 0.71, which is higher than transformer of 0.55, which proves diff outperforms transformer in this evaluation. \n",
    "\n",
    "As for the diff performance in general, it shows relative big errors that is mainly due to the distribution of the ottawa dataset is significantly different with the NASA dataset. Fine tune of the model shall be necessary to achieve better performance.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
